import os
import re
import time
import zipfile
import datetime
from openai import OpenAI
from typing import Any, List, Tuple, Optional
import requests
import streamlit as st
from dotenv import find_dotenv, load_dotenv

# LangChain / OpenAI / Transformers imports
from langchain_classic.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from transformers import pipeline

# -------------------- Environment --------------------
load_dotenv(find_dotenv())
HUGGINGFACE_API_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# -------------------- Utilities --------------------
def safe_filename(name: str) -> str:
    """Make a filesystem-safe filename from original filename (no extension)."""
    name = re.sub(r"[^\w\s-]", "", name).strip().lower()
    name = re.sub(r"[-\s]+", "_", name)
    return name or "file"

def timestamp_now(fmt: str = "%Y%m%d_%H%M%S") -> str:
    return datetime.datetime.now().strftime(fmt)

def progress_sleep(iterations: int, step_delay: float = 0.02):
    """Small helper to animate progress (used for UX)."""
    for _ in range(iterations):
        time.sleep(step_delay)

# -------------------- AI Pipelines --------------------
# Initialize model pipelines lazily to avoid heavy startup cost if not used.
_image_to_text_pipeline = None
def image_to_text_pipeline():
    global _image_to_text_pipeline
    if _image_to_text_pipeline is None:
        _image_to_text_pipeline = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
    return _image_to_text_pipeline

def generate_text_from_image(image_path: str) -> str:
    """Return caption generated by BLIP model."""
    pipe = image_to_text_pipeline()
    result = pipe(image_path)
    # Transformers pipeline returns a list of dicts; get generated_text
    return result[0].get("generated_text", "").strip()

def generate_story_from_text(scenario: str) -> str:
    """Return a short story from GPT via LangChain/ChatOpenAI."""
    prompt_template = """
You are a concise, creative storyteller. Write a vivid, engaging short story (maximum 50 words)
based on the following scene description.

CONTEXT: {scenario}

STORY:
"""
    prompt = PromptTemplate(template=prompt_template, input_variables=["scenario"])
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.8)
    chain = LLMChain(llm=llm, prompt=prompt, verbose=False)
    return chain.predict(scenario=scenario).strip()

def generate_speech_from_text(message: str, out_path: str = "generated_audio.mp3"):
    """
    Generate speech from text using OpenAI TTS.
    :param message: text or story to convert
    :param out_path: output path (mp3 or wav)
    :return: output file path or None on failure
    """
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        # Create speech
        with client.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts",  # high-quality text-to-speech model
            voice="alloy",            # voices: alloy, verse, shimmer, coral, etc.
            input=message
        ) as response:
            response.stream_to_file(out_path)

        print(f"‚úÖ OpenAI TTS audio saved to {out_path}")
        return out_path
    except Exception as e:
        print(f"‚ùå Error generating speech: {e}")
        return None

def create_zip_for_batch(items: List[Tuple[str, str, Optional[str]]]) -> str:
    """
    items: list of tuples (image_filepath, story_txt_path, audio_path or None)
    returns path to zip file
    """
    ts = timestamp_now()
    zip_name = f"stories_{ts}.zip"
    with zipfile.ZipFile(zip_name, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for img, txt, aud in items:
            if img and os.path.exists(img):
                zf.write(img, arcname=os.path.basename(img))
            if txt and os.path.exists(txt):
                zf.write(txt, arcname=os.path.basename(txt))
            if aud and os.path.exists(aud):
                zf.write(aud, arcname=os.path.basename(aud))
    return zip_name

# -------------------- Streamlit UI --------------------
def main() -> None:
    st.set_page_config(page_title="Image-to-Story AI | Dwaipayan Labs", page_icon="üéôÔ∏è", layout="wide")
    # ---- CSS: corporate dark + neon glow + loader typing effect ----
    st.markdown(
        """
        <style>
        /* Page */
        body, .stApp { background-color: #0b0b0c; color: #e6eef3; font-family: Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial; }
        h1, h2, h3 { color: #bfefff; }

        /* Sidebar */
        [data-testid="stSidebar"] { background-color: #121214; border-right: 1px solid #222; box-shadow: 4px 0 30px rgba(0,0,0,0.6); }
        [data-testid="stSidebar"] img { border-radius: 8px; }

        /* Upload box (neon) */
        .upload-box {
            border: 2px dashed rgba(0,180,216,0.35);
            background: linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.02));
            padding: 28px;
            border-radius: 14px;
            text-align: center;
            box-shadow: 0 0 30px rgba(0,180,216,0.04);
        }

        /* Buttons */
        .stButton>button {
            background: linear-gradient(90deg,#00b4d8,#007fff);
            color: #000;
            font-weight: 700;
            border-radius: 10px;
            padding: 10px 22px;
            box-shadow: 0 6px 20px rgba(0,180,216,0.12);
            border: none;
        }
        .stButton>button:hover { transform: translateY(-2px); box-shadow: 0 10px 30px rgba(0,180,216,0.18); }

        /* Story card glow */
        .story-card {
            background-color: #131316;
            border-radius: 12px;
            padding: 14px;
            border: 1px solid rgba(0,180,216,0.18);
            box-shadow: 0 0 30px rgba(0,180,216,0.03);
            margin-bottom: 12px;
        }

        /* Neon image outline */
        .stImage img {
            border-radius: 12px;
            border: 2px solid rgba(0,180,216,0.9);
            box-shadow: 0 0 30px rgba(0,180,216,0.12);
        }

        /* Small loader */
        .loader { border: 3px solid #111; border-top: 3px solid #00b4d8; border-radius: 50%; width: 14px; height: 14px; animation: spin 1s linear infinite; display:inline-block; margin-right:8px; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        /* Footer */
        .footer { text-align:center; color:#9aa6ad; margin-top:32px; font-size:0.9rem; border-top:1px solid rgba(255,255,255,0.03); padding-top:16px; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ---- Sidebar ----
    with st.sidebar:
        st.image("img/app_header.jpg", use_container_width=True)
        st.markdown("**Built by Dwaipayan Chatterjee**")
        st.markdown("Powered by OpenAI, LangChain, Hugging Face & Streamlit.")
        st.caption("Version 3.0 ‚Ä¢ Multi-image batch export")

    # ---- Header ----
    st.markdown("<h1 style='text-align:center'>üñºÔ∏è StoryLens ‚Äì Every picture tells a story. </h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center;color:#9aa6ad'>Upload multiple images, click Generate, and download a ZIP with each image, story (.txt) and audio (.mp3).</p>", unsafe_allow_html=True)
    st.markdown("---")

    # ---- Multi-file uploader ----
    # st.markdown('<div class="upload-box"><h4>üì§ Upload images (JPG / JPEG / PNG)</h4><p style="color:#9aa6ad">You can upload multiple files at once.</p></div>', unsafe_allow_html=True)
    uploaded_files = st.file_uploader("", type=["jpg", "jpeg", "png"], accept_multiple_files=True, label_visibility="collapsed")

    if uploaded_files and len(uploaded_files) > 0:
        st.markdown(f"**{len(uploaded_files)} file(s) selected.**")
        # show thumbnails in a horizontal layout
        cols = st.columns(min(4, len(uploaded_files)))
        for idx, f in enumerate(uploaded_files):
            with cols[idx % len(cols)]:
                st.image(f, use_container_width=True, caption=f.name)

        # Generate button
        if st.button("üöÄ Generate Stories for all images"):
            # Prepare output container
            overall_progress = st.progress(0)
            status_placeholder = st.empty()
            results_container = st.container()

            ts_run = timestamp_now()
            processed_items = []  # tuples of (image_path, txt_path, audio_path)
            total = len(uploaded_files)
            completed = 0

            # Create temp directory for this run
            out_dir = f"stories_{ts_run}"
            os.makedirs(out_dir, exist_ok=True)

            for idx, uploaded in enumerate(uploaded_files, start=1):
                base, ext = os.path.splitext(uploaded.name)
                safe_base = safe_filename(base)
                item_ts = timestamp_now()
                image_path = os.path.join(out_dir, f"{safe_base}{ext.lower()}")
                # write image to disk
                with open(image_path, "wb") as imgf:
                    imgf.write(uploaded.getvalue())

                # update status
                status_placeholder.markdown(f"<div><span class='loader'></span>Processing **{uploaded.name}** ‚Äî analyzing image...</div>", unsafe_allow_html=True)
                progress_sleep(12, 0.02)

                # 1) Caption
                try:
                    caption = generate_text_from_image(image_path)
                except Exception as e:
                    caption = ""
                    st.error(f"Failed to generate caption for {uploaded.name}: {e}")

                # 2) Story
                status_placeholder.markdown(f"<div><span class='loader'></span>Generating story for **{uploaded.name}**...</div>", unsafe_allow_html=True)
                progress_sleep(8, 0.02)
                try:
                    story = generate_story_from_text(caption or "A photo")
                except Exception as e:
                    story = "Story generation failed."
                    st.error(f"Failed to generate story for {uploaded.name}: {e}")

                # Save story text file
                story_txt_path = os.path.join(out_dir, f"{safe_base}_story_{item_ts}.txt")
                try:
                    with open(story_txt_path, "w", encoding="utf-8") as tf:
                        tf.write("IMAGE DESCRIPTION:\n")
                        tf.write((caption or "N/A") + "\n\n")
                        tf.write("STORY:\n")
                        tf.write(story)
                except Exception as e:
                    st.error(f"Failed to write story file for {uploaded.name}: {e}")

                # 3) TTS
                status_placeholder.markdown(f"<div><span class='loader'></span>Converting story to speech ‚Äî {uploaded.name}...</div>", unsafe_allow_html=True)
                progress_sleep(6, 0.02)

                # Prepare audio filename (use .mp3 for OpenAI TTS)
                audio_path = os.path.join(out_dir, f"{safe_base}_speech_{item_ts}.mp3")

                # Generate audio (OpenAI). This function returns the path or None.
                generated_audio_path = generate_speech_from_text(story, audio_path)

                if generated_audio_path and os.path.exists(generated_audio_path):
                    st.success(f"‚úÖ Audio generated for {uploaded.name}")
                else:
                    st.warning(f"‚ö†Ô∏è Audio generation failed for {uploaded.name}")

                # Append processed item (audio may be None)
                processed_items.append((image_path, story_txt_path, generated_audio_path if (generated_audio_path and os.path.exists(generated_audio_path)) else None))

                # Update progress
                completed += 1
                overall_progress.progress(int(completed / total * 100))
                # small gap for UX
                time.sleep(0.3)

            status_placeholder.empty()

            # Create ZIP
            status_msg = st.info("üì¶ Creating ZIP package...")
            zip_path = create_zip_for_batch([
                (img, txt, aud) for img, txt, aud in processed_items if img or txt or aud
            ])
            status_msg.empty()

            # Show results ‚Äî for each processed image, show story + audio if available
            with results_container:
                st.markdown("## ‚úÖ Generation results")
                for img, txt, aud in processed_items:
                    container = st.container()
                    cols = container.columns([1, 2])
                    with cols[0]:
                        if os.path.exists(img):
                            st.image(img, use_container_width=True)
                    with cols[1]:
                        # story display
                        if os.path.exists(txt):
                            with open(txt, "r", encoding="utf-8") as tf:
                                story_text = tf.read()
                            st.markdown(f"<div class='story-card'><pre style='white-space:pre-wrap'>{story_text}</pre></div>", unsafe_allow_html=True)
                        # audio playback if present
                        if aud and os.path.exists(aud):
                            with open(aud, "rb") as audio_file:
                                audio = audio_file.read()
                            ext = os.path.splitext(aud)[1].lower()
                            print(aud)
                            # choose format param by extension
                            ext = os.path.splitext(aud)[1].lower()
                            if ext == ".mp3":
                                st.audio(audio, format="audio/mp3")
                            elif ext == ".flac":
                                st.audio(audio, format="audio/flac")
                            else:
                                st.audio(audio)
                        else:
                            st.warning("No audio produced for this item.")

            # Download button for zip
            if os.path.exists(zip_path):
                with open(zip_path, "rb") as zf:
                    st.download_button(
                        label="‚¨áÔ∏è Download all stories (ZIP)",
                        data=zf,
                        file_name=os.path.basename(zip_path),
                        mime="application/zip",
                    )
            st.success("All done ‚Äî package ready!")

    else:
        st.info("Upload one or more images to begin. When ready, click **Generate Stories for all images**.")

    st.markdown("<div class='footer'>¬© 2025 Dwaipayan Chatterjee ‚Ä¢ Powered by OpenAI, Langchain, Hugging Face & Streamlit</div>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()